{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RayNCode/code_collab/blob/main/XGB_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7e58hofB62gm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"https://raw.githubusercontent.com/RayNCode/code_collab/main/project-3-files\""
      ],
      "metadata": {
        "id": "NAH_6GogaNzF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_dataset = pd.read_csv(f\"{data_url}/learn_dataset.csv\").copy()\n",
        "learn_dataset_Emp_contract = pd.read_csv(f\"{data_url}/learn_dataset_Emp_contract.csv\").copy()\n",
        "learn_dataset_sport = pd.read_csv(f\"{data_url}/learn_dataset_sport.csv\").copy()\n",
        "learn_dataset_job = pd.read_csv(f\"{data_url}/learn_dataset_job.csv\").copy()\n",
        "\n",
        "code_work_description_map = pd.read_csv(f\"{data_url}/code_work_description_map.csv\").copy()\n",
        "city_adm = pd.read_csv(f\"{data_url}/city_adm.csv\").copy()\n",
        "code_Club = pd.read_csv(f\"{data_url}/code_Club.csv\").copy()\n",
        "departments = pd.read_csv(f\"{data_url}/departments.csv\").copy()\n",
        "\n",
        "test_dataset_job = pd.read_csv(f\"{data_url}/test_dataset_job.csv\").copy()\n",
        "test_dataset = pd.read_csv(f\"{data_url}/test_dataset.csv\").copy()\n",
        "test_dataset_Emp_contract = pd.read_csv(f\"{data_url}/test_dataset_Emp_contract.csv\").copy()\n",
        "test_dataset_sport = pd.read_csv(f\"{data_url}/test_dataset_sport.csv\").copy()"
      ],
      "metadata": {
        "id": "xJcT5tKBaHkS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_base(learn_dataset_job, work_desc, learn_dataset, dept_code, emp_contract, learn_dataset_sport, code_club, departments):\n",
        "    # Chargement et fusion des datasets de travail\n",
        "    merged_df = pd.merge(learn_dataset_job, work_desc, left_on='work_description', right_on='N3', how='left')\n",
        "\n",
        "    # Conversion des colonnes N2, N1 et N3 en chaînes de caractères\n",
        "    merged_df['N2'] = merged_df['N2'].astype(str)\n",
        "    merged_df['N1'] = merged_df['N1'].astype(str)\n",
        "    merged_df['N3'] = merged_df['N3'].astype(str)\n",
        "\n",
        "    # Remplir les valeurs manquantes\n",
        "    merged_df['N2'].fillna(merged_df['N3'].str[:-2], inplace=True)\n",
        "    merged_df['N1'].fillna(merged_df['N2'].str[:-1], inplace=True)\n",
        "\n",
        "    # Fusion avec d'autres datasets\n",
        "    data_2 = pd.merge(learn_dataset, merged_df, on=\"Id\", how=\"left\")\n",
        "    df_1 = data_2.merge(dept_code, on='insee_code')\n",
        "    df_2 = df_1.merge(emp_contract, on='Id', how='left')\n",
        "    df_3 = df_2.merge(learn_dataset_sport, on='Id', how='left')\n",
        "    df_4 = df_3.merge(code_Club, left_on='Club', right_on='Code', how='left')\n",
        "    final_df = df_4.merge(departments, on='dep', how='left')\n",
        "\n",
        "    # Conversion de type pour les colonnes 'Categorie' et 'REG'\n",
        "    final_df['Categorie'] = final_df['Categorie'].astype(str)\n",
        "    final_df['Categorie'] = final_df['Categorie'].astype('object')\n",
        "    final_df['REG'] = final_df['REG'].astype(str)\n",
        "    final_df['REG'] = final_df['REG'].astype('object')\n",
        "\n",
        "    # Création et application d'une condition pour filtrer et imputer des valeurs\n",
        "    condition = (final_df['ACTIVITY_TYPE'] != \"TYPE1|1\")\n",
        "    final_df.loc[condition, ['EMOLUMENT', 'Working_hours']] = 0.0\n",
        "    # Traitement des valeurs manquantes dans les colonnes catégorielles\n",
        "    categorical_columns = final_df.select_dtypes(include=['object']).columns\n",
        "    final_df[categorical_columns] = final_df[categorical_columns].fillna(\"None\")\n",
        "\n",
        "\n",
        "    return final_df\n"
      ],
      "metadata": {
        "id": "3_U-oHI37lNP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_learn_test(final_df): #ajouter l'ID quelque part\n",
        "    # Séparer la variable cible si elle est présente\n",
        "    if 'target' in final_df.columns:\n",
        "        y = final_df['target'].copy()\n",
        "        y = np.where(y == 'B', 1, 0)\n",
        "        X = final_df.drop(['target'], axis='columns')\n",
        "    else:\n",
        "        X = final_df.copy()\n",
        "        X_test_id = X['Id'].copy()\n",
        "\n",
        "    # Suppression des colonnes non nécessaires\n",
        "    X = X.drop([\"Id\", 'Nom de la commune', 'Nom fédération', 'Nom catégorie', 'Nom du département', 'Code'], axis=\"columns\")\n",
        "\n",
        "    if 'target' in final_df.columns:\n",
        "      return X, y\n",
        "    else:\n",
        "      return X, X_test_id\n",
        "\n"
      ],
      "metadata": {
        "id": "ldQlzwI2-5PV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_dataset_base = preprocess_data_base(learn_dataset_job, code_work_description_map, learn_dataset, city_adm, learn_dataset_Emp_contract, learn_dataset_sport, code_Club, departments)\n",
        "test_dataset_base = preprocess_data_base(test_dataset_job, code_work_description_map, test_dataset, city_adm, test_dataset_Emp_contract, test_dataset_sport, code_Club,departments)"
      ],
      "metadata": {
        "id": "EHI6cVyVAbf1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = preprocess_learn_test(learn_dataset_base)\n",
        "X_test, X_test_id = preprocess_learn_test(test_dataset_base)\n",
        "print(\"Shape de X_train:\", X_train.shape)\n",
        "print(\"Shape de y_test:\", y_train.shape)\n",
        "print(\"Shape de X_test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "piqVKOBPicYK",
        "outputId": "e7b27e14-0d3c-4e69-bc6f-0574d2c16665",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de X_train: (49993, 27)\n",
            "Shape de y_test: (49993,)\n",
            "Shape de X_test: (49992, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mélange de X_train et y_train\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)"
      ],
      "metadata": {
        "id": "4sfhR3eeEpY0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètres pour XGBClassifier\n",
        "xgb_params = {\n",
        "    'subsample': 0.9000000000000001,\n",
        "    'scale_pos_weight': 0.8300000000000001,\n",
        "    'reg_lambda': 0.08,\n",
        "    'reg_alpha': 0.8,\n",
        "    'n_estimators': 151,\n",
        "    'min_child_weight': 3.279999999999994,\n",
        "    'max_depth': 5,\n",
        "    'max_delta_step': 1.54,\n",
        "    'learning_rate': 0.76,\n",
        "    'gamma': 0.9980000000000002,\n",
        "    'colsample_bytree': 0.7100000000000001,\n",
        "    'colsample_bylevel': 0.9400000000000002\n",
        "}"
      ],
      "metadata": {
        "id": "LTA8i6y5JjUI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(X_train, X_test):\n",
        "    # Transformer de colonnes pour le prétraitement\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('imputer', IterativeImputer(estimator=RandomForestRegressor(), max_iter=100, random_state=0), ['Working_hours', 'EMOLUMENT']),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'), ['insee_code', \"is_student\", \"OCCUPATION_42\", \"ACTIVITY_TYPE\", \"household\", \"sex\", \"employer_category\", \"job_category\", \"Terms_of_emp\", \"Eco_sect\", \"Job_dep\", \"WORK_CONDITION\", \"work_description\", \"N3\", \"N2\", \"N1\", \"town_type\", \"dep\", \"Emp_contract\", \"Club\", \"Categorie\", 'REG']),\n",
        "            ('ordinal', OrdinalEncoder(), [\"Highest_degree\", \"EMPLOYEE_COUNT\"])\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    # Appliquer le prétraitement sur X_train et X_test\n",
        "    X_train_preprocessed = preprocessing.fit_transform(X_train)\n",
        "    X_test_preprocessed = preprocessing.transform(X_test)\n",
        "\n",
        "    xgb_classifier = XGBClassifier(random_state=42, **xgb_params)\n",
        "    xgb_classifier.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "    return  xgb_classifier, preprocessing, X_train_preprocessed, X_test_preprocessed\n",
        "\n",
        "# Utilisation de la fonction\n",
        "xgb_classifier, preprocessing, X_train_preprocessed, X_test_preprocessed = process_data(X_train, X_test)\n"
      ],
      "metadata": {
        "id": "vzlXW-8PsUdg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape de X_test:\", X_train_preprocessed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJpS3zruiu_R",
        "outputId": "53e24a29-733a-477c-e8c2-2b8ce0010d94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de X_test: (49993, 14740)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape de X_test:\", X_test_preprocessed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coCAG1oTcIY5",
        "outputId": "a170ed26-c829-4408-9e47-ba056cbdb0ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de X_test: (49992, 14740)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = xgb_classifier.predict(X_test_preprocessed)"
      ],
      "metadata": {
        "id": "iWcfnyb5bL75"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir les prédictions numériques en étiquettes catégorielles\n",
        "predictions_labels = np.where(predictions == 1, 'B', 'G')\n",
        "\n",
        "# Créer un DataFrame avec les Ids et les prédictions\n",
        "results_df = pd.DataFrame({\n",
        "    'Id': X_test_id,\n",
        "    'target': predictions_labels\n",
        "})\n",
        "\n",
        "#Include your directory\n",
        "results_df.to_csv(\"/content/predictions.csv\", index=False)\n",
        "# Calcul du décompte des valeurs pour les prédictions\n",
        "value_counts = results_df['target'].value_counts()\n",
        "\n",
        "# Affichage du décompte\n",
        "print(value_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "4SM_uQ7ybX6D",
        "outputId": "5f5b3881-3462-4652-a2d4-01d3fb7135d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B    30329\n",
            "G    19663\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}